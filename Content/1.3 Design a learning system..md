---
tags:
  - ML
Date: 2025-09-14
Relevant: https://www.youtube.com/watch?v=mzBR0hbN2Uk
---
Build a system based on data to resolve a reality demands.

1. Data is the most important part, so when selecting a training set, consider whether it:

	- Have label or not?
	- Can it characterize the whole data space (Does this sample have enough key features do determine the label - for instance: An intruision logs can have some features like active at abnormal hour like 3 AM) - good for future prediction.

2. Determine the type of the function:

	- $F: X \to {0; 1}$
	- $F: X \to$ set of labels
	- $F: X \to R$

3. Choosing model.

	- Linear?
	- Decision Tree?
	- Neural Network?

>[!tip] No-free-lunch theorem
>No algorithm can beat another on all domains.

=> We have to choose the best algorithm for each specific problem.

4. Training data.

	- How many samples are enough?
	- How to handle noise/disrupted?
	- Size of training set affect the performance or not?

5. Learnability.

	- Limit of each learning algorithm?
	- The generalization of the system? (Use finite knowledge to make predictions on new observations or generate new knowledge).
	- Avoid overfitting?

> Overfitting: Learn by rote - like some students can solve 2 + x = 3 because they memorize it, if the problem turn into 3 + x = 3, they can't find x - similar to this.

>[!tip] Concept of overfitting.
>The model perform well on training set but on future data (unknown/new data) - their performance downgrade extremely.

---
## Cause of overfitting.

- Model is too complicated (too many features on the training set, too much parameters).
- Noises or errors in training data.
- Training size is too small, not enough for model to learn and character the whole data space.

![[Pasted image 20250914230706.png]]


---
### How to resolve overfitting?

**Regularization**.

Among many functions - the function mapping $F: x \to$ {} (models), which one produces the best performance, which one can generalize best from training data?

- Generalization is the **main target** of ML - predict well on unseen data (future data).

