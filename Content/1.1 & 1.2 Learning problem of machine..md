---
tags:
  - "#ML"
Date: 2025-09-13
Video: https://www.youtube.com/watch?v=Ohp4bL8egME&t=1166s
---

Data collection -> Data Preprocessing -> Data Visualization & Grasping -> Hypothesis Testing -> Insights & Policy Decision.

3 first phases get 70-90% total time.

A subfield of AI.

>[!quote] 
>We say that a machine *learn* when it can improves its performance *P* on task *T* through the experience *E*.

## Instance.

Spam filtering for emails.

T: Filter spam/non-spam emails.
P: Accuracy of prediction based on true label (in case we have 3 spam, 2 non-spam, model predict correct 1 spam email and 4 non-spam -> its accuracy is $\frac{1+2}{5}$ = 60%).
E: Experience through set of old emails with the true label (It learn that the spam email has any characteristics like grammar errors,...).

---
## What does a machine learn?

A mapping function:

$f: x\to y$

- x - observations from the past (samples, observations, data) - past experience.
- y - prediction, new knowledge, new experience.

From experience (data) $\to$ generate new knowledge, new prediction on a new test.

---
## Where does it learn from?

Learning from a training samples/observations/data points {${x_{1}, x_{2}, \dots x_{n}}$} ; {$y_{1}, y_{2}, \dots{y_{m}}$}.

- $x_{i}$ is an observation of $x$ in the past.
- $y_{i}$ is an observation of $y$ in the past (aka _output, label, response_)

### After learning.

We obtain a model, new knowledge, new experience - ($f$).

Use this model to do *prediction or inference*  for future observations.

$$
y = f(x)
$$
The function space has unlimited functions (2D, 3D, .... N_D) - we can't by ourselves finding this function $\to$ only machine can do.

---
# Two basic learning problems.

## Supervised learning.

Learn a function $y = f(x)$ from a given training set {${x_{1}, x_{2}, \dots x_{n}}$} ; {$y_{1}, y_{2}, \dots{y_{m}}$} so that $y_{i} \cong f(x_{i})$

It means, the model when learning from many sets of $x$ - let's say spam email and non-spam email characteristics, it can define whether an email is spam or not by several features like too many grammar errors (?) - and make a prediction $y_{i}$ for the $x_{i}$ based on its training knowledge.

- Classification - $y_{i}$ belongs to a discrete set {spam; normal}.
- Regression - $y_{i}$ belongs to a continuous set {0, 1, 2, 3, 4...}.

>[!tip]
>If 2 outputs of y can be used for comparision (<, >, =) -> Regression problem.


## Unsupervised learning.

Learn a function $y = f(x)$ from a given training set $x_{1}, x_{2}, \dots x_{n}$ 
We have no true label in this case.

>[!question]
>What does *true label* mean?
>Like, you have an equation 2 + 3 = 5, it should have a label - correct or not for this equation so that model can learn.

- y can be a data cluster, hidden structure or a trend.

For instance: Clustering a data into clusters.

![[Pasted image 20250914224158.png]]

> Community detection, trends detection (detect future needs, demands in fashion for instance).

Other: Semi-Supervised learning, Reinforcement Learning.

----
### Supervised learning: Classification.

#### Multi-class classification.

The output $y$ only belongs to a predefined labels {$c_{1}, c_{2}, \dots c_{n}$}

>1 output $y$ belongs to only 1 class, and 1 sample $x$ only belongs to 1 label.

For instance:
- Spam filtering: {spam; non-spam}

#### Multi-label classification.

The output $y$ is a subset of labels.

> 1 output $y$ is a set of classes, 1 sample $x$ can belongs to multi-label.

Imagine tagging: $y$ = {bird, nest, tree} - an image contains 3 objects - 3 labels.

Sentiment analysis.

![[Pasted image 20250914223934.png]]

There are 3 words (3 labels) can describe this image.

#### Supervised learning: Regression.

Prediction: stock price.






