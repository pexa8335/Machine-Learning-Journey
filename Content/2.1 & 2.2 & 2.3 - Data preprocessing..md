---
tags:
  - ML
Date: 2025-09-16
Relevant: https://www.youtube.com/watch?v=tVMyB7rIP-k&list=PLaKukjQCR56ZRh2cAkweftiZCF2sTg11_&index=4
Relevant_2: https://www.youtube.com/watch?v=3lrGTZUZhWM&list=PLaKukjQCR56ZRh2cAkweftiZCF2sTg11_&index=5
Relevant_3: https://www.youtube.com/watch?v=MoDz6cuGHn0&list=PLaKukjQCR56ZRh2cAkweftiZCF2sTg11_&index=6
---
>[!tip] Time Budget
>Data collecting, cleaning, mining,... ~80%

Data mining: scrapping, logging, crawling.
Data cleaning: filtering noise, numerizing (convert data from categorized data into numeric data so that the machine can learn), fill missing values.

The sampling data should cover the entire context of the domain we want the model to learn.
Data should be *general* and not *biased* towards a small part of the domain.

![[Pasted image 20250916115506.png]]

**Missing Value Imputation Techniques:**
- Manual Imputation
- Impute with Mean
- Impute with Mode
- Impute with Predicted Values (e.g., using Bayes, Regression models)

---
## Technique: Transforming.

### Semantics.

Extract semantic features.

![[Pasted image 20250916120801.png]]

---
### Decrease data size.

>[!tip] Advantages:
>- Increase learning process, reduce data to learn, reduce noises...

- Feature selection: remove unnecessary features.
- Dimension reduction: PCA, ICA, LDA... (Algorithm) to transform original data into less-dimension data.
- Abstraction: raw data is converted to abstracted concepts, for instance, temperature is expressed numerically $\to$ use {hot, cold, neutral} to represent it.

